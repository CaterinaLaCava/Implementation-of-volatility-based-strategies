{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file performs the unzipping of the files, it creates a single data frame for every asset and saves it in the data folder\n",
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import tarfile\n",
    "import xlrd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functions import *\n",
    "import re\n",
    "import dask\n",
    "import vaex\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_tickers contains the name of all the files/stocks\n",
    "stock_tickers_bbo = get_file_names('data/raw/sp100_2004-8/bbo')\n",
    "stock_tickers_bbo.remove('.DS_Store') \n",
    "for file_name_bbo in stock_tickers_bbo:\n",
    "    file_path_bbo = f\"data/raw/sp100_2004-8/bbo/{file_name_bbo}/{file_name_bbo}_bbo.tar\"\n",
    "    output_path_bbo = f\"data/raw/sp100_2004-8/bbo/{file_name_bbo}/\"\n",
    "    extract_tar(file_path_bbo, output_path_bbo)\n",
    "\n",
    "\n",
    "stock_tickers_trade = get_file_names('data/raw/sp100_2004-8/trade')\n",
    "stock_tickers_trade.remove('.DS_Store') \n",
    "for file_name_trade in stock_tickers_trade:\n",
    "    file_path_trade = f\"data/raw/sp100_2004-8/trade/{file_name_trade}/{file_name_trade}_trade.tar\"\n",
    "    output_path_trade = f\"data/raw/sp100_2004-8/trade/{file_name_trade}/\"\n",
    "    extract_tar(file_path_trade, output_path_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler=\"processes\")\n",
    "\n",
    "@dask.delayed\n",
    "def load_TRTH_trade(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             only_non_special_trades=True,\n",
    "             only_regular_trading_hours=True,\n",
    "             open_time=\"09:30:00\",\n",
    "             close_time=\"16:00:00\",\n",
    "             merge_sub_trades=True):\n",
    "    try:\n",
    "        if re.search('(csv|csv\\\\.gz)$',filename):\n",
    "            DF = pd.read_csv(filename, engine = \"pyarrow\")\n",
    "        if re.search(r'arrow$',filename):\n",
    "            DF = pd.read_arrow(filename)\n",
    "        if re.search('parquet$',filename):\n",
    "            DF = pd.read_parquet(filename)\n",
    "    except Exception as e:\n",
    "     #   print(\"load_TRTH_trade could not load \"+filename)\n",
    "     #   print(e)\n",
    "        return None\n",
    "    try:\n",
    "        DF.shape\n",
    "    except Exception as e: # DF does not exist\n",
    "        print(\"DF does not exist\")\n",
    "        print(e)\n",
    "        return None\n",
    "    if DF.shape[0]==0:\n",
    "        return None\n",
    "    if only_non_special_trades:\n",
    "        DF = DF[DF[\"trade-stringflag\"]==\"uncategorized\"]\n",
    "    DF.drop(columns=[\"trade-rawflag\",\"trade-stringflag\"],axis=1,inplace=True)\n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"d\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(open_time,close_time)    # warning: ever heard e.g. about Thanksgivings?\n",
    "    if merge_sub_trades:\n",
    "           DF=DF.groupby(DF.index).agg(trade_price=pd.NamedAgg(column='trade-price', aggfunc='mean'),\n",
    "                                       trade_volume=pd.NamedAgg(column='trade-volume', aggfunc='sum'))\n",
    "    return DF\n",
    "\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def load_TRTH_bbo(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             only_regular_trading_hours=True,\n",
    "             merge_sub_trades=True):\n",
    "    try:\n",
    "        if re.search(r'(csv|csv\\.gz)$',filename):\n",
    "            DF = pd.read_csv(filename)\n",
    "        if re.search(r'arrow$',filename):\n",
    "            DF = pd.read_arrow(filename)\n",
    "        if re.search(r'parquet$',filename):\n",
    "            DF = pd.read_parquet(filename) \n",
    "    except Exception as e:\n",
    "       # print(\"load_TRTH_bbo could not load \"+filename)\n",
    "        return None\n",
    "    try:\n",
    "        DF.shape\n",
    "    except Exception as e: # DF does not exist\n",
    "        print(\"DF does not exist\")\n",
    "        print(e)\n",
    "        return None\n",
    "    if DF.shape[0]==0:\n",
    "        return None\n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"d\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(\"09:30:00\",\"16:00:00\")    # ever heard about Thanksgivings?\n",
    "    if merge_sub_trades:\n",
    "        DF=DF.groupby(DF.index).last()\n",
    "    return DF\n",
    "\n",
    "@dask.delayed\n",
    "def load_merge_trade_bbo(ticker,date,\n",
    "                         dirBase=\"data/raw/sp100_2004-8/\",\n",
    "                         suffix=\"csv.gz\",\n",
    "                         suffix_save=None,\n",
    "                         dirSaveBase=\"data/clean/sp100_2004-8/events\",\n",
    "                         saveOnly=False,\n",
    "                         doSave=False\n",
    "                        ):\n",
    "    \n",
    "    file_trade=dirBase+\"/\"+\"/trade/\"+ticker+\"/\"+str(date.date())+\"-\"+ticker+\"-trade.\"+suffix\n",
    "    file_bbo=file_trade.replace(\"trade\",\"bbo\")\n",
    "    trades=load_TRTH_trade(file_trade)\n",
    "    bbos  =load_TRTH_bbo(file_bbo)\n",
    "    try:\n",
    "        trades.shape + bbos.shape\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    events=trades.join(bbos,how=\"outer\")\n",
    "    \n",
    "    if doSave:\n",
    "        dirSave=dirSaveBase+\"/\"+\"/events/\"+ticker\n",
    "        if not os.path.isdir(dirSave):\n",
    "            os.makedirs(dirSave)\n",
    "\n",
    "        if suffix_save:\n",
    "            suffix=suffix_save\n",
    "        \n",
    "        file_events=dirSave+\"/\"+str(date.date())+\"-\"+ticker+\"-events\"+\".\"+suffix\n",
    "       # pdb.set_trace()\n",
    "\n",
    "        saved=False\n",
    "        if suffix==\"arrow\":\n",
    "            events=vaex.from_pandas(events,copy_index=True)\n",
    "            events.export_arrow(file_events)\n",
    "            saved=True\n",
    "        if suffix==\"parquet\":\n",
    "         #   pdb.set_trace()\n",
    "            events.to_parquet(file_events,use_deprecated_int96_timestamps=True)\n",
    "            saved=True\n",
    "            \n",
    "        if not saved:\n",
    "            print(\"suffix \"+suffix+\" : format not recognized\")\n",
    "            \n",
    "        if saveOnly:\n",
    "            return saved\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_to_parquet(ticker):\n",
    "    if ~os.path.exists(f\"data/clean/sp100_2004-8/{ticker}.parquet\"):\n",
    "        trade_files=glob.glob(f\"data/raw/sp100_2004-8/trade/{ticker}/*.csv.gz\")\n",
    "        trade_files.sort()\n",
    "        allpromises=[load_TRTH_trade(fn) for fn in trade_files]\n",
    "        trades=dask.compute(allpromises)[0]\n",
    "        trades=pd.concat(trades)\n",
    "\n",
    "        bbo_files=glob.glob(f\"data/raw/sp100_2004-8/bbo/{ticker}/*.csv.gz\")\n",
    "        bbo_files.sort()\n",
    "        allpromises=[load_TRTH_bbo(fn) for fn in bbo_files]\n",
    "        bbos=dask.compute(allpromises)[0]\n",
    "        bbos=pd.concat(bbos)\n",
    "\n",
    "        events=trades.join(bbos,how=\"outer\")\n",
    "\n",
    "        # Filling NaNs in 'ask_price' column with the last known value from 'ask_price' column\n",
    "        events = events.replace('()', np.nan)\n",
    "        events['ask-price'] = events['ask-price'].bfill()\n",
    "        events['bid-price'] = events['bid-price'].bfill()\n",
    "        events['ask-volume'] = events['ask-volume'].bfill()\n",
    "        events['bid-volume'] = events['bid-volume'].bfill()\n",
    "        events['ask-price'] = events['ask-price'].ffill()\n",
    "        events['bid-price'] = events['bid-price'].ffill()\n",
    "        events['ask-volume'] = events['ask-volume'].ffill()\n",
    "        events['bid-volume'] = events['bid-volume'].ffill()\n",
    "\n",
    "        events = events.dropna(subset=['trade_price'])\n",
    "        events[\"bid-price\"] = events[\"bid-price\"].values.astype(\"float\")\n",
    "        events[\"bid-volume\"]=events[\"bid-volume\"].values.astype(\"float\")\n",
    "        events[\"ask-price\"]=events[\"ask-price\"].values.astype(\"float\")\n",
    "        events[\"ask-volume\"]=events[\"ask-volume\"].values.astype(\"float\")\n",
    "\n",
    "        events.to_parquet(f\"data/clean/sp100_2004-8/{ticker}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_file_names(\"data/raw/sp100_2004-8/trade/\")\n",
    "tickers.remove('.DS_Store') #I have no '.DS_Store'file\n",
    "tickers.remove('MSFT.O')\n",
    "tickers.remove('ORCL.N')\n",
    "\n",
    "for ticker in tickers:\n",
    "    data_to_parquet(ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
