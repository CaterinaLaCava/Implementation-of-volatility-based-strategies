{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file performs the unzipping of the files, it creates a single data frame for every asset and saves it in the data folder\n",
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import tarfile\n",
    "import xlrd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns an array of strings, where each string is the name of a file in the folder passed as argument\n",
    "def get_file_names(folder):\n",
    "    file_names = []\n",
    "    for file in os.listdir(folder):\n",
    "        file_names.append(file)\n",
    "    return file_names\n",
    "\n",
    "#define a function that creates a file in the data folder, it takes as argument the name of the file and the content of the file\n",
    "def create_file(file_name, content):\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "#this function takes as argument the name of a tar file file_path and uncompress it and store the content in the repertory output_path\n",
    "def extract_tar(file_path, output_path):\n",
    "    #Extracts the contents of a .tar file to the specified output path.\n",
    "    #Args:\n",
    "    #file_path: The path to the .tar file.\n",
    "    #output_path: The path where the contents of the .tar file will be extracted.\n",
    "    try:\n",
    "        with tarfile.open(file_path, 'r') as tar:\n",
    "            tar.extractall(output_path)\n",
    "        print(f\"Extraction of {file_path} successful.\")\n",
    "    except tarfile.TarError as e:\n",
    "        print(f\"Error extracting {file_path}: {e}\")\n",
    "\n",
    "def extract_csv_gz_file(source_file, destination_directory):\n",
    "    \"\"\"\n",
    "    Extracts a .csv.gz file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "    - source_file: The path to the .csv.gz file to be extracted.\n",
    "    - destination_directory: The directory where the extracted file will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "    try:\n",
    "        file_name = os.path.basename(source_file)\n",
    "        output_file = os.path.join(destination_directory, os.path.splitext(file_name)[0])\n",
    "        with gzip.open(source_file, 'rb') as f_in, open(output_file, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "        print(f\"File extracted to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting file: {e}\")\n",
    "\n",
    "def xl_to_datetime(xltime):\n",
    "    #transform xltime into an object datetime\n",
    "    date_value = int(xltime)\n",
    "    time_value = (xltime - date_value) * 24 * 60 * 60  # Convert fraction of a day to seconds\n",
    "    date_tuple = xlrd.xldate_as_tuple(date_value, 0)  # 0 for 1900-based date system\n",
    "    year, month, day, hour, minute, second = date_tuple\n",
    "    date_time_obj = datetime.datetime(year, month, day, hour, minute, second) + datetime.timedelta(seconds=time_value)\n",
    "    return date_time_obj\n",
    "\n",
    "def convert_to_float(value):\n",
    "    #converts the value to float if it is possible, otherwise it returns nan\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return float_value if np.isfinite(float_value) else np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "def resample_df(df):\n",
    "    #resample the dataframe df to 1 minute frequency\n",
    "    #one apply the function xl_to_datetime to the column xltime of merged_df\n",
    "    df['datetime'] = df['xltime'].apply(xl_to_datetime)\n",
    "    df['bid-price'] = df['bid-price'].astype(float)\n",
    "    df['ask-price'] = df['ask-price'].astype(float)\n",
    "    df['bid-volume'] = df['bid-volume'].astype(float)\n",
    "    df['ask-volume'] = df['ask-volume'].astype(float)\n",
    "    #one drops the column xltime\n",
    "    df = df.drop(columns=['xltime'])\n",
    "    #one sets the column datetime as index\n",
    "    df = df.set_index('datetime')\n",
    "    df = df.resample('1T').agg({\n",
    "        'bid-price': 'mean',\n",
    "        'ask-price': 'mean',\n",
    "        'bid-volume': 'sum',\n",
    "        'ask-volume': 'sum'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def create_folder(directory_path, folder_name):\n",
    "    # Combine directory path and folder name to create the full path for the new folder\n",
    "    new_folder_path = os.path.join(directory_path, folder_name)\n",
    "\n",
    "    # Create the new folder if it doesn't already exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_tickers contains the name of all the files/stocks\n",
    "stock_tickers = get_file_names('data/raw/sp100_2004-8/bbo')\n",
    "# remove .DS_Store from the list: I dont know why but there exists a .DS_Store file in the folder when using function get_file_names\n",
    "# stock_tickers.remove('.DS_Store') I have no '.DS_Store'file \n",
    " \n",
    "# len stock_tickers = 87 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction of data/raw/sp100_2004-8/bbo/AA.N/AA.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/ABT.N/ABT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/AEP.N/AEP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/ALL.N/ALL.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/APA.N/APA.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/AVP.N/AVP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/AXP.N/AXP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BA.N/BA.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BAC.N/BAC.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BAX.N/BAX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BHI.N/BHI.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BK.N/BK.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/BMY.N/BMY.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/C.N/C.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/CAT.N/CAT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/CL.N/CL.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/COF.N/COF.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/COP.N/COP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/CVS.N/CVS.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/CVX.N/CVX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/DD.N/DD.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/DIS.N/DIS.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/DOW.N/DOW.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/DVN.N/DVN.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/EMC.N/EMC.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/EMR.N/EMR.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/ETR.N/ETR.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/EXC.N/EXC.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/F.N/F.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/FCX.N/FCX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/FDX.N/FDX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/GD.N/GD.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/GE.N/GE.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/GS.N/GS.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/HAL.N/HAL.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/HD.N/HD.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/HNZ.N/HNZ.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/HON.N/HON.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/HPQ.N/HPQ.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/IBM.N/IBM.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/JNJ.N/JNJ.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/JPM.N/JPM.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/KFT.N/KFT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/KO.N/KO.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/LMT.N/LMT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/LOW.N/LOW.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MA.N/MA.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MCD.N/MCD.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MDT.N/MDT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MET.N/MET.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MMM.N/MMM.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MO.N/MO.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MON.N/MON.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MRK.N/MRK.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MS.N/MS.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/MSFT.O/MSFT.O_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/NKE.N/NKE.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/NOV.N/NOV.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/NSC.N/NSC.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/ORCL.N/ORCL.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/OXY.N/OXY.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/PEP.N/PEP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/PFE.N/PFE.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/PG.N/PG.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/PM.N/PM.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/RTN.N/RTN.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/S.N/S.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/SLB.N/SLB.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/SO.N/SO.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/T.N/T.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/TGT.N/TGT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/TWX.N/TWX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/TXN.N/TXN.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/UNH.N/UNH.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/UNP.N/UNP.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/UPS.N/UPS.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/USB.N/USB.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/UTX.N/UTX.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/V.N/V.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/VZ.N/VZ.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/WAG.N/WAG.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/WFC.N/WFC.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/WMB.N/WMB.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/WMT.N/WMT.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/WY.N/WY.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/XOM.N/XOM.N_bbo.tar successful.\n",
      "Extraction of data/raw/sp100_2004-8/bbo/XRX.N/XRX.N_bbo.tar successful.\n"
     ]
    }
   ],
   "source": [
    "# this cell opens the tar file that contains all the data for each particular stock. \n",
    "# the result is a folder for each stock that contains all the data for that stock (for each date)\n",
    "for file_name in stock_tickers:\n",
    "    file_path = f\"data/raw/sp100_2004-8/bbo/{file_name}/{file_name}_bbo.tar\"\n",
    "    output_path = f\"data/raw/sp100_2004-8/bbo/{file_name}/\"\n",
    "    extract_tar(file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell creates the data frame for each stock and saves it in the data folder. it also resamples the data to 1 minute frequency\n",
    "# observe that it does not uncompress the file. it just reads the compressed file and creates the data frame\n",
    "\n",
    "asset_names = get_file_names('data/raw/sp100_2004-8/bbo')\n",
    "# remove .DS_Store from the list\n",
    "# asset_names.remove('.DS_Store')\n",
    "for asset_name in asset_names:\n",
    "    names = get_file_names(f\"data/raw/sp100_2004-8/bbo/{asset_name}\")\n",
    "    # remove names that are not ending with .csv.gz\n",
    "    names = [file for file in names if file.endswith('.csv.gz')]\n",
    "    resampled_df = pd.DataFrame()\n",
    "    for file_name in names:\n",
    "        df = pd.read_csv(f\"data/raw/sp100_2004-8/bbo/{asset_name}/{file_name}\")\n",
    "        df = df.apply(lambda x: x.apply(convert_to_float))\n",
    "        #df = df.fillna(method='ffill')\n",
    "        df = resample_df(df)\n",
    "        resampled_df = pd.concat([resampled_df, df])\n",
    "    # one sorts the index of resampled_df\n",
    "    resampled_df = resampled_df.sort_index()\n",
    "    create_folder('data/cleaned', asset_name)\n",
    "    resampled_df.to_parquet(f\"data/cleaned/{asset_name}/{asset_name}.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
